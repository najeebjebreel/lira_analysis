{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ab7a072",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "# LiRA Membership Inference Attack Analysis\n",
    "\n",
    "This notebook performs comprehensive analysis of membership inference attacks using\n",
    "the Likelihood Ratio Attack (LiRA) framework.\n",
    "\n",
    "## Analysis Pipeline:\n",
    "1. **Two-Mode Evaluation**: Compare target vs shadow threshold strategies\n",
    "2. **Performance Metrics**: TPR/FPR at operating points, AUC, precision with priors\n",
    "3. **Vulnerability Analysis**: Identify samples consistently vulnerable to inference\n",
    "4. **Visualization**: Generate publication-quality figures and tables\n",
    "\n",
    "## Key Concepts:\n",
    "- **Target Mode**: Each model uses its own ROC-derived threshold (upper bound)\n",
    "- **Shadow Mode**: Each model uses median threshold from other models (transferability)\n",
    "- **Vulnerability**: Samples with FP=0 (never false alarm) and TP>0 (detected when member)\n",
    "\n",
    "Author: Najeeb Jebreel, optmized by Cloude Sonnet 4.5\n",
    "Date: 2025\n",
    "\"\"\"\n",
    "\n",
    "## 1. Import Libraries and Set Up Configurations\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import yaml\n",
    "from pathlib import Path\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# Import analysis utilities\n",
    "from analysis_utils import *\n",
    "from metrics import *\n",
    "\n",
    "import os\n",
    "os.environ['KMP_DUPLICATE_LIB_OK'] = 'TRUE'\n",
    "\n",
    "### Configure Analysis Parameters\n",
    "\n",
    "class Config:\n",
    "    \"\"\"Central configuration for analysis.\"\"\"\n",
    "    \n",
    "    # Experiment location\n",
    "    EXP_PATH = Path(\"d:/mona/lira_analysis/experiments/cifar10/resnet18/2025-10-20_1828\")\n",
    "    \n",
    "    # Operating points for evaluation\n",
    "    TARGET_FPRS = [0.00001, 0.001]  # 0.001% and 0.1% FPR\n",
    "    \n",
    "    # Membership priors for precision computation\n",
    "    PRIORS = [0.01, 0.1, 0.5]  # 1%, 10%, 50% membership rates\n",
    "    \n",
    "    # Quality control\n",
    "    DO_SANITY_CHECKS = True  # Validate threshold extraction\n",
    "    \n",
    "    # Attack variants to evaluate\n",
    "    SCORE_FILES = {\n",
    "        \"LiRA (online)\": \"online_scores_leave_one_out.npy\",\n",
    "        \"LiRA (online, fixed var)\": \"online_fixed_scores_leave_one_out.npy\",\n",
    "        \"LiRA (offline)\": \"offline_scores_leave_one_out.npy\",\n",
    "        \"LiRA (offline, fixed var)\": \"offline_fixed_scores_leave_one_out.npy\",\n",
    "        \"Global threshold\": \"global_scores_leave_one_out.npy\",\n",
    "    }\n",
    "    \n",
    "    LABELS_FILE = \"membership_labels.npy\"\n",
    "    \n",
    "    # Vulnerability analysis\n",
    "    VULN_ATTACK = \"LiRA (online)\"\n",
    "    VULN_FPR = 1e-5  # 0.001% FPR\n",
    "\n",
    "config = Config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "265d4030",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output directory: analysis_results\\cifar10\\resnet18\\2025-10-31_1828\n",
      "\n",
      "Loading experiment data...\n",
      "✓ Loaded 10 models × 60000 samples\n",
      "✓ Attacks: ['LiRA (online)', 'LiRA (online, fixed var)', 'LiRA (offline)', 'LiRA (offline, fixed var)', 'Global threshold']\n"
     ]
    }
   ],
   "source": [
    "## 2. Load Experiment Data\n",
    "\n",
    "# Setup output directory\n",
    "out_dir = create_output_directory(config.EXP_PATH)\n",
    "print(f\"Output directory: {out_dir}\\n\")\n",
    "\n",
    "# Load membership labels and attack scores\n",
    "print(\"Loading experiment data...\")\n",
    "labels, scores = load_experiment_data(\n",
    "    config.EXP_PATH,\n",
    "    config.SCORE_FILES,\n",
    "    config.LABELS_FILE\n",
    ")\n",
    "\n",
    "M, N = labels.shape\n",
    "print(f\"✓ Loaded {M} models × {N} samples\")\n",
    "print(f\"✓ Attacks: {list(scores.keys())}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "09721979",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating target and shadow modes...\n",
      "Evaluating LiRA (online)...\n",
      "Evaluating LiRA (online, fixed var)...\n",
      "Evaluating LiRA (offline)...\n",
      "Evaluating LiRA (offline, fixed var)...\n",
      "Evaluating Global threshold...\n",
      "✓ Saved: analysis_results\\cifar10\\resnet18\\2025-10-31_1828\\per_model_metrics_two_modes.csv\n",
      "\n",
      "Generating summary statistics...\n",
      "✓ Saved: analysis_results\\cifar10\\resnet18\\2025-10-31_1828\\summary_statistics_two_modes.csv\n",
      "\n",
      "Sample Results (Target Mode, Prior=0.5):\n",
      "                   attack  Target FPR (%)  TPR_Mean  AUC_Mean\n",
      "         Global threshold           0.001     0.003    50.269\n",
      "         Global threshold           0.100     0.100    50.269\n",
      "           LiRA (offline)           0.001     0.003    50.095\n",
      "           LiRA (offline)           0.100     0.108    50.095\n",
      "LiRA (offline, fixed var)           0.001     0.002    49.666\n"
     ]
    }
   ],
   "source": [
    "## 3. Two-Mode Evaluation\n",
    "\n",
    "### Evaluate Target and Shadow Modes\n",
    "\"\"\"\n",
    "**Target Mode**: Each model uses its own threshold derived from its ROC curve.\n",
    "This represents the upper bound on attack performance (attacker knows everything).\n",
    "\n",
    "**Shadow Mode**: Each model uses the median threshold from other models.\n",
    "This represents realistic transferability (attacker uses shadow models).\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def evaluate_two_modes(labels, scores, target_fprs, priors, do_sanity_checks=True):\n",
    "    \"\"\"\n",
    "    Evaluate attacks in both target and shadow modes.\n",
    "    \n",
    "    For each (attack, target_fpr) pair:\n",
    "    1. Compute per-model target thresholds from individual ROCs\n",
    "    2. Compute shadow thresholds as median of other models' thresholds\n",
    "    3. Evaluate confusion matrices at both threshold types\n",
    "    4. Compute metrics for all membership priors\n",
    "    \"\"\"\n",
    "    M, N = labels.shape\n",
    "    all_results = []\n",
    "    \n",
    "    for attack_name, score_array in scores.items():\n",
    "        print(f\"Evaluating {attack_name}...\")\n",
    "        \n",
    "        # Precompute AUC (threshold-independent)\n",
    "        aucs = np.full(M, np.nan)\n",
    "        for m in range(M):\n",
    "            try:\n",
    "                aucs[m] = roc_auc_score(labels[m].astype(int), score_array[m])\n",
    "            except ValueError:\n",
    "                pass  # Handle single-class edge case\n",
    "        \n",
    "        for target_fpr in target_fprs:\n",
    "            # Step 1: Compute target thresholds (per-model optimal)\n",
    "            target_taus = np.empty(M)\n",
    "            achieved_fprs = np.full(M, np.nan)\n",
    "            achieved_tprs = np.full(M, np.nan)\n",
    "            \n",
    "            for m in range(M):\n",
    "                tau, fpr_val, tpr_val = find_threshold_at_fpr(\n",
    "                    score_array[m], labels[m], target_fpr\n",
    "                )\n",
    "                target_taus[m] = tau\n",
    "                if fpr_val is not None:\n",
    "                    achieved_fprs[m] = fpr_val\n",
    "                    achieved_tprs[m] = tpr_val\n",
    "            \n",
    "            # Step 2: Compute shadow thresholds (median of others)\n",
    "            shadow_taus = np.array([\n",
    "                compute_shadow_thresholds(target_taus, m) for m in range(M)\n",
    "            ])\n",
    "            \n",
    "            # Step 3: Optional validation\n",
    "            if do_sanity_checks:\n",
    "                finite_models = np.where(np.isfinite(target_taus))[0]\n",
    "                for m in finite_models[:5]:  # Check first 5\n",
    "                    is_valid = validate_threshold(\n",
    "                        score_array[m], labels[m], target_taus[m],\n",
    "                        achieved_fprs[m], achieved_tprs[m]\n",
    "                    )\n",
    "                    if not is_valid:\n",
    "                        print(f\"  [WARNING] Model {m} @ {target_fpr}: validation failed\")\n",
    "            \n",
    "            # Step 4: Evaluate both modes\n",
    "            for mode, taus in [('target', target_taus), ('shadow', shadow_taus)]:\n",
    "                # Skip shadow mode for baseline Global threshold\n",
    "                if mode == 'shadow' and attack_name == \"Global threshold\":\n",
    "                    continue\n",
    "                \n",
    "                for m in range(M):\n",
    "                    tau = taus[m]\n",
    "                    \n",
    "                    # Compute confusion matrix\n",
    "                    if not np.isfinite(tau):\n",
    "                        tp, fp = 0, 0\n",
    "                        tn = int(np.sum(~labels[m]))\n",
    "                        fn = int(np.sum(labels[m]))\n",
    "                        tpr, fpr_achieved = 0.0, 0.0\n",
    "                    else:\n",
    "                        tp, fp, tn, fn, tpr, fpr_achieved = compute_confusion_matrix(\n",
    "                            score_array[m], labels[m], tau\n",
    "                        )\n",
    "                    \n",
    "                    # Compute precision for each prior\n",
    "                    for prior in priors:\n",
    "                        precision = compute_precision_from_rates(tpr, fpr_achieved, prior)\n",
    "                        \n",
    "                        all_results.append({\n",
    "                            'mode': mode,\n",
    "                            'attack': attack_name,\n",
    "                            'target_fpr': target_fpr,\n",
    "                            'achieved_fpr': fpr_achieved,\n",
    "                            'prior': prior,\n",
    "                            'model_idx': m,\n",
    "                            'threshold': tau,\n",
    "                            'tp': tp, 'fp': fp, 'tn': tn, 'fn': fn,\n",
    "                            'tpr': tpr,\n",
    "                            'precision': precision,\n",
    "                            'auc': aucs[m]\n",
    "                        })\n",
    "    \n",
    "    return pd.DataFrame(all_results)\n",
    "\n",
    "\n",
    "print(\"\\nEvaluating target and shadow modes...\")\n",
    "detail_df = evaluate_two_modes(\n",
    "    labels, scores,\n",
    "    config.TARGET_FPRS,\n",
    "    config.PRIORS,\n",
    "    config.DO_SANITY_CHECKS\n",
    ")\n",
    "\n",
    "# Save detailed results\n",
    "detail_path = out_dir / \"per_model_metrics_two_modes.csv\"\n",
    "detail_df.to_csv(detail_path, index=False)\n",
    "print(f\"✓ Saved: {detail_path}\")\n",
    "\n",
    "\n",
    "### Aggregate Summary Statistics\n",
    "\n",
    "def create_summary_statistics(detail_df):\n",
    "    \"\"\"Aggregate per-model results into summary statistics.\"\"\"\n",
    "    summary = (detail_df\n",
    "        .groupby(['mode', 'attack', 'target_fpr', 'prior'], as_index=False)\n",
    "        .agg(\n",
    "            TPR_Mean=('tpr', 'mean'),\n",
    "            TPR_Std=('tpr', 'std'),\n",
    "            FPR_Achieved_Mean=('achieved_fpr', 'mean'),\n",
    "            FPR_Achieved_Std=('achieved_fpr', 'std'),\n",
    "            Precision_Mean=('precision', 'mean'),\n",
    "            Precision_Std=('precision', 'std'),\n",
    "            AUC_Mean=('auc', 'mean'),\n",
    "            AUC_Std=('auc', 'std')\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    # Convert to percentages\n",
    "    pct_cols = ['TPR_Mean', 'TPR_Std', 'FPR_Achieved_Mean', 'FPR_Achieved_Std',\n",
    "                'Precision_Mean', 'Precision_Std', 'AUC_Mean', 'AUC_Std']\n",
    "    for col in pct_cols:\n",
    "        summary[col] = (summary[col] * 100).round(3)\n",
    "    \n",
    "    # Add readable target FPR\n",
    "    summary['Target FPR (%)'] = (summary['target_fpr'] * 100).round(4)\n",
    "    summary = summary.drop(columns=['target_fpr'])\n",
    "    \n",
    "    # Reorder columns\n",
    "    summary = summary[[\n",
    "        'mode', 'attack', 'Target FPR (%)', 'prior',\n",
    "        'TPR_Mean', 'TPR_Std',\n",
    "        'FPR_Achieved_Mean', 'FPR_Achieved_Std',\n",
    "        'Precision_Mean', 'Precision_Std',\n",
    "        'AUC_Mean', 'AUC_Std'\n",
    "    ]]\n",
    "    \n",
    "    return summary\n",
    "\n",
    "\n",
    "print(\"\\nGenerating summary statistics...\")\n",
    "summary_df = create_summary_statistics(detail_df)\n",
    "\n",
    "# Save summary\n",
    "summary_path = out_dir / \"summary_statistics_two_modes.csv\"\n",
    "summary_df.to_csv(summary_path, index=False)\n",
    "print(f\"✓ Saved: {summary_path}\")\n",
    "\n",
    "# Display sample results\n",
    "print(\"\\nSample Results (Target Mode, Prior=0.5):\")\n",
    "sample = summary_df[\n",
    "    (summary_df['mode'] == 'target') & \n",
    "    (summary_df['prior'] == 0.5)\n",
    "][['attack', 'Target FPR (%)', 'TPR_Mean', 'AUC_Mean']].head()\n",
    "print(sample.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "95320a47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Analyzing per-sample vulnerability (LiRA (online) @ 1e-05)...\n",
      "✓ Saved: analysis_results\\cifar10\\resnet18\\2025-10-31_1828\\samples_vulnerability_ranked_online_shadow_0p001pct.csv\n",
      "✓ Saved: analysis_results\\cifar10\\resnet18\\2025-10-31_1828\\samples_highly_vulnerable_online_shadow_0p001pct.csv\n",
      "\n",
      "Statistics:\n",
      "  Total samples: 60000\n",
      "  Highly vulnerable (FP=0, TP>0): 5\n",
      "  Most vulnerable: TP=2, FP=0\n"
     ]
    }
   ],
   "source": [
    "## 4. Per-Sample Vulnerability Analysis\n",
    "\n",
    "\"\"\"\n",
    "**Vulnerability Metric**: For each sample, count TP/FP across leave-one-out models.\n",
    "\n",
    "- **Highly Vulnerable**: FP=0 (never falsely flagged) AND TP>0 (detected when member)\n",
    "- **Most Vulnerable**: Lowest FP, then highest TP (stable and detectable)\n",
    "\"\"\"\n",
    "\n",
    "def compute_sample_vulnerability(detail_df, scores, labels, attack_name, target_fpr):\n",
    "    \"\"\"\n",
    "    Compute per-sample confusion statistics across models.\n",
    "    \n",
    "    Uses shadow thresholds to evaluate realistic attack scenarios.\n",
    "    \"\"\"\n",
    "    # Extract shadow thresholds for this attack/FPR\n",
    "    mask = (\n",
    "        (detail_df['mode'] == 'shadow') &\n",
    "        (detail_df['attack'] == attack_name) &\n",
    "        (np.isclose(detail_df['target_fpr'], target_fpr, atol=1e-12))\n",
    "    )\n",
    "    \n",
    "    shadow_info = detail_df.loc[mask, ['model_idx', 'threshold']].drop_duplicates(\n",
    "        subset=['model_idx']\n",
    "    )\n",
    "    \n",
    "    if shadow_info.empty:\n",
    "        raise ValueError(f\"No shadow thresholds for {attack_name} @ {target_fpr}\")\n",
    "    \n",
    "    # Build threshold array\n",
    "    M, N = scores[attack_name].shape\n",
    "    thresholds = np.full(M, np.inf)\n",
    "    for _, row in shadow_info.iterrows():\n",
    "        m = int(row['model_idx'])\n",
    "        if 0 <= m < M:\n",
    "            thresholds[m] = float(row['threshold'])\n",
    "    \n",
    "    # Generate predictions\n",
    "    predictions = scores[attack_name] >= thresholds[:, None]  # [M, N]\n",
    "    labels_bool = labels.astype(bool)\n",
    "    \n",
    "    # Count per sample\n",
    "    tp = np.sum(predictions & labels_bool, axis=0).astype(int)\n",
    "    fp = np.sum(predictions & ~labels_bool, axis=0).astype(int)\n",
    "    tn = np.sum(~predictions & ~labels_bool, axis=0).astype(int)\n",
    "    fn = np.sum(~predictions & labels_bool, axis=0).astype(int)\n",
    "    \n",
    "    return pd.DataFrame({\n",
    "        'sample_id': np.arange(N),\n",
    "        'tp': tp,\n",
    "        'fp': fp,\n",
    "        'tn': tn,\n",
    "        'fn': fn\n",
    "    })\n",
    "\n",
    "\n",
    "def rank_vulnerable_samples(sample_df):\n",
    "    \"\"\"Rank by vulnerability: low FP (stable), then high TP (detectable).\"\"\"\n",
    "    ranked = sample_df.sort_values(by=['fp', 'tp'], ascending=[True, False])\n",
    "    highly_vulnerable = sample_df[(sample_df['fp'] == 0) & (sample_df['tp'] > 0)]\n",
    "    return ranked, highly_vulnerable\n",
    "\n",
    "\n",
    "print(f\"\\nAnalyzing per-sample vulnerability ({config.VULN_ATTACK} @ {config.VULN_FPR})...\")\n",
    "sample_vuln = compute_sample_vulnerability(\n",
    "    detail_df, scores, labels,\n",
    "    config.VULN_ATTACK,\n",
    "    config.VULN_FPR\n",
    ")\n",
    "\n",
    "vuln_ranked, highly_vuln = rank_vulnerable_samples(sample_vuln)\n",
    "\n",
    "# Save rankings\n",
    "vuln_path = out_dir / \"samples_vulnerability_ranked_online_shadow_0p001pct.csv\"\n",
    "vuln_ranked.to_csv(vuln_path, index=False)\n",
    "\n",
    "high_vuln_path = out_dir / \"samples_highly_vulnerable_online_shadow_0p001pct.csv\"\n",
    "highly_vuln.to_csv(high_vuln_path, index=False)\n",
    "\n",
    "print(f\"✓ Saved: {vuln_path}\")\n",
    "print(f\"✓ Saved: {high_vuln_path}\")\n",
    "print(f\"\\nStatistics:\")\n",
    "print(f\"  Total samples: {len(vuln_ranked)}\")\n",
    "print(f\"  Highly vulnerable (FP=0, TP>0): {len(highly_vuln)}\")\n",
    "\n",
    "if len(vuln_ranked) > 0:\n",
    "    top = vuln_ranked.iloc[0]\n",
    "    print(f\"  Most vulnerable: TP={top['tp']}, FP={top['fp']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "80e1267a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generating visualization...\n",
      "Saved grid: analysis_results\\cifar10\\resnet18\\2025-10-31_1828\\top20_vulnerable_online_shadow_0p001pct.png\n",
      "✓ Saved vulnerability visualization\n"
     ]
    }
   ],
   "source": [
    "## 5. Visualization\n",
    "\n",
    "print(\"\\nGenerating visualization...\")\n",
    "cfg_path = config.EXP_PATH / \"attack_config.yaml\"\n",
    "\n",
    "if cfg_path.exists():\n",
    "    with open(cfg_path, 'r') as f:\n",
    "        exp_config = yaml.safe_load(f)\n",
    "    \n",
    "    full_dataset, _ = load_dataset(exp_config)\n",
    "    \n",
    "    display_top_k_vulnerable_samples(\n",
    "        vulnerable_samples=vuln_ranked,\n",
    "        full_dataset=full_dataset,\n",
    "        k=20,\n",
    "        nrow=5,\n",
    "        out_dir=out_dir,\n",
    "        save_name=\"top20_vulnerable_online_shadow_0p001pct.png\",\n",
    "        font_size=7,\n",
    "        badge_margin=2,\n",
    "        overhang_left=3,\n",
    "        overhang_up=4\n",
    "    )\n",
    "    print(\"✓ Saved vulnerability visualization\")\n",
    "else:\n",
    "    print(\"⚠ Config not found, skipping visualization\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e81d758c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "ANALYSIS COMPLETE\n",
      "============================================================\n",
      "\n",
      "Output directory: analysis_results\\cifar10\\resnet18\\2025-10-31_1828\n",
      "\n",
      "Generated files:\n",
      "  • per_model_metrics_two_modes.csv - Detailed per-model results\n",
      "  • summary_statistics_two_modes.csv - Aggregated statistics\n",
      "  • samples_vulnerability_ranked_online_shadow_0p001pct.csv - All samples ranked\n",
      "  • samples_highly_vulnerable_online_shadow_0p001pct.csv - High-risk samples\n",
      "  • top20_vulnerable_online_shadow_0p001pct.png - Visualization\n",
      "\n",
      "✓ All analyses completed successfully!\n"
     ]
    }
   ],
   "source": [
    "## 6. Summary\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"ANALYSIS COMPLETE\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\nOutput directory: {out_dir}\")\n",
    "print(f\"\\nGenerated files:\")\n",
    "print(f\"  • per_model_metrics_two_modes.csv - Detailed per-model results\")\n",
    "print(f\"  • summary_statistics_two_modes.csv - Aggregated statistics\")\n",
    "print(f\"  • samples_vulnerability_ranked_online_shadow_0p001pct.csv - All samples ranked\")\n",
    "print(f\"  • samples_highly_vulnerable_online_shadow_0p001pct.csv - High-risk samples\")\n",
    "print(f\"  • top20_vulnerable_online_shadow_0p001pct.png - Visualization\")\n",
    "print(\"\\n✓ All analyses completed successfully!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lira-analysis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
