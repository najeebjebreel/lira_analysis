{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7a10491d-178c-4aec-9ebf-dd4fa916262c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================= Imports =======================================\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "from itertools import combinations\n",
    "import shutil\n",
    "from matplotlib.ticker import MaxNLocator, PercentFormatter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47a8740c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nStability across seeds & training variations — publication-grade figures.\\n\\nExports (PDFs only):\\n  figures/\\n    jaccard_noleg.pdf          # Panel A (Avg. Jaccard), no legend\\n    intersection.pdf           # Panel B (Avg. intersection)\\n    union.pdf                  # Panel C (Avg. union)\\n    legend.pdf                 # shared legend (thin strip)\\ntables/\\n  stability_7scenarios.csv     # exact numbers used in plots\\n\\nScenarios & labels:\\n  - \"Identical (2–5 seeds)\"\\n  - \"+1 different (BS=512, Drop=0.2)\"\\n  - \"+1 different (Drop=0.25, WD=3e-3)\"\\n  - \"+1 different (Arch)\"\\n  - \"+1 different (TL)\"\\n  - \"+2 different\"              # average over all variant pairs\\n  - \"+3 different\"              # average over all variant triplets\\n'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ============================= YOU FILL THESE ================================\n",
    "INPUTS = {\n",
    "    # Identical seeds — weak_rotate_jitter_cutmix_drop0.1_wd1e-3_seed{0,7,42,123,1234}\n",
    "    \"seed0\":    \"cifar10/resnet18/weak_rotate_jitter_cutmix_drop0.1_wd1e-3_seed0\",\n",
    "    \"seed7\":    \"cifar10/resnet18/weak_rotate_jitter_cutmix_drop0.1_wd1e-3_seed7\",\n",
    "    \"seed42\":   \"cifar10/resnet18/weak_rotate_jitter_cutmix_drop0.1_wd1e-3_seed42\",\n",
    "    \"seed123\":  \"cifar10/resnet18/weak_rotate_jitter_cutmix_drop0.1_wd1e-3_seed123\",\n",
    "    \"seed1234\": \"cifar10/resnet18/weak_rotate_jitter_cutmix_drop0.1_wd1e-3_seed1234\",\n",
    "\n",
    "    # +1 different (BS=512, Drop=0.2)\n",
    "    \"diff_bs_drop\": \"cifar10/resnet18/weak_rotate_jitter_cutmix_drop0.2_wd1e-3_bs512\",\n",
    "\n",
    "    # +1 different (Drop=0.25, WD=3e-3)\n",
    "    \"diff_drop_wd\": \"cifar10/resnet18/weak_rotate_jitter_cutmix_drop0.25_wd3e-3\",\n",
    "\n",
    "    # +1 different (Arch)\n",
    "    \"diff_arch\": \"cifar10/wrn28-2/weak_rotate_jitter_cutmix_drop0.1_wd1e-3\",\n",
    "\n",
    "    # +1 different (TL)\n",
    "    \"transfer\": \"cifar10/efficientnetv2_rw_s/pretrained_weak_rotate_jitter_cutmix_drp0.25_wd_5e-2\",\n",
    "}\n",
    "\n",
    "CSV_BASENAME = \"samples_vulnerability_ranked_online_shadow_0p001pct.csv\"\n",
    "SAMPLE_ID_COL = \"sample_id\"\n",
    "\n",
    "\n",
    "\n",
    "# ---------------------------- Outputs ---------------------------------------\n",
    "OUT_FIG_DIR = \"figures\"\n",
    "OUT_TAB_DIR = \"tables\"\n",
    "os.makedirs(OUT_FIG_DIR, exist_ok=True)\n",
    "os.makedirs(OUT_TAB_DIR, exist_ok=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "75534931",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Generated 4 essential figures:\n",
      "  figures/jaccard_noleg.pdf\n",
      "  figures/intersection.pdf\n",
      "  figures/union.pdf\n",
      "  figures/legend.pdf\n",
      "✓ Table: tables/stability_7scenarios.csv\n"
     ]
    }
   ],
   "source": [
    "# ---- IEEE-friendly font setup with auto-fallback (Windows-safe) -------------\n",
    "BASE_FONTSIZE = 8.5\n",
    "PAPER_USES_TIMES = True\n",
    "HAS_TEX = shutil.which(\"latex\") is not None\n",
    "\n",
    "if HAS_TEX:\n",
    "    mpl.rcParams.update({\n",
    "        \"text.usetex\": True,\n",
    "        \"pdf.fonttype\": 42, \"ps.fonttype\": 42,\n",
    "        \"axes.labelsize\": BASE_FONTSIZE,\n",
    "        \"axes.titlesize\": BASE_FONTSIZE,\n",
    "        \"xtick.labelsize\": BASE_FONTSIZE - 1,\n",
    "        \"ytick.labelsize\": BASE_FONTSIZE - 1,\n",
    "        \"legend.fontsize\": BASE_FONTSIZE - 1,\n",
    "        \"figure.titlesize\": BASE_FONTSIZE,\n",
    "        \"font.family\": \"serif\",\n",
    "        \"text.latex.preamble\": r\"\\usepackage{newtxtext}\\usepackage{newtxmath}\" if PAPER_USES_TIMES else r\"\",\n",
    "    })\n",
    "else:\n",
    "    mpl.rcParams.update({\n",
    "        \"text.usetex\": False,\n",
    "        \"pdf.fonttype\": 42, \"ps.fonttype\": 42,\n",
    "        \"axes.labelsize\": BASE_FONTSIZE,\n",
    "        \"axes.titlesize\": BASE_FONTSIZE,\n",
    "        \"xtick.labelsize\": BASE_FONTSIZE - 1,\n",
    "        \"ytick.labelsize\": BASE_FONTSIZE - 1,\n",
    "        \"legend.fontsize\": BASE_FONTSIZE - 1,\n",
    "        \"figure.titlesize\": BASE_FONTSIZE,\n",
    "        \"font.family\": \"serif\",\n",
    "        \"font.serif\": [\"Times New Roman\", \"Times\", \"DejaVu Serif\", \"CMU Serif\", \"Nimbus Roman\"],\n",
    "        \"mathtext.fontset\": \"stix\" if PAPER_USES_TIMES else \"cm\",\n",
    "    })\n",
    "\n",
    "\n",
    "# ============================= Utilities =====================================\n",
    "def _csv_path(p: str | Path) -> Path:\n",
    "    \"\"\"Return a real CSV path whether user provided a directory or a CSV file.\"\"\"\n",
    "    p = Path(p)\n",
    "    if p.is_dir():\n",
    "        p = p / CSV_BASENAME\n",
    "    if p.suffix.lower() != \".csv\":\n",
    "        raise FileNotFoundError(f\"Expected a directory or CSV; got: {p}\")\n",
    "    if not p.exists():\n",
    "        raise FileNotFoundError(f\"CSV not found: {p}\")\n",
    "    return p\n",
    "\n",
    "def to_id_set(path_or_dir: str | Path, col=SAMPLE_ID_COL, tp_threshold: int = 1) -> set[str]:\n",
    "    \"\"\"Load CSV and return set of sample IDs where TP >= tp_threshold.\"\"\"\n",
    "    csvp = _csv_path(path_or_dir)\n",
    "    df = pd.read_csv(csvp)\n",
    "    if col not in df.columns:\n",
    "        raise KeyError(f\"Expected '{col}' in {csvp}; got {list(df.columns)}\")\n",
    "    if \"tp\" not in df.columns:\n",
    "        raise KeyError(f\"Expected 'tp' column in {csvp}\")\n",
    "    filtered = df[df[\"tp\"] >= tp_threshold]\n",
    "    return set(filtered[col].dropna().astype(str))\n",
    "\n",
    "\n",
    "# Dynamic Y-limits computed from the data\n",
    "def _nice_bounds_numeric(ymin, ymax):\n",
    "    span = ymax - ymin\n",
    "    pad = 0.05 * max(1.0, span)\n",
    "    lo = ymin - pad\n",
    "    hi = ymax + pad\n",
    "    rng = hi - lo\n",
    "    if   rng <= 20:  step = 1\n",
    "    elif rng <= 100: step = 5\n",
    "    elif rng <= 500: step = 10\n",
    "    elif rng <= 2000: step = 50\n",
    "    else:            step = 100\n",
    "    lo = np.floor(lo / step) * step\n",
    "    hi = np.ceil(hi / step) * step\n",
    "    return lo, hi\n",
    "\n",
    "def _nice_bounds_percent(ymin, ymax):\n",
    "    lo = max(0.0, ymin - 0.02)\n",
    "    hi = min(1.0, ymax + 0.02)\n",
    "    lo = np.floor(lo * 20) / 20.0\n",
    "    hi = np.ceil(hi * 20) / 20.0\n",
    "    if np.isclose(lo, hi):\n",
    "        hi = min(1.0, lo + 0.05)\n",
    "    return lo, hi\n",
    "\n",
    "def compute_dynamic_ylims(df):\n",
    "    yl = {}\n",
    "    col = df[\"avg_jaccard\"].dropna()\n",
    "    yl[\"avg_jaccard\"] = _nice_bounds_percent(col.min(), col.max()) if not col.empty else (0, 1)\n",
    "    col = df[\"avg_intersection\"].dropna()\n",
    "    yl[\"avg_intersection\"] = _nice_bounds_numeric(col.min(), col.max()) if not col.empty else (0, 1)\n",
    "    col = df[\"avg_union\"].dropna()\n",
    "    yl[\"avg_union\"] = _nice_bounds_numeric(col.min(), col.max()) if not col.empty else (0, 1)\n",
    "    return yl\n",
    "\n",
    "\n",
    "# ============================= Metrics =======================================\n",
    "def avg_agreement(named_sets, k):\n",
    "    j, inter, uni = [], [], []\n",
    "    for combo in combinations(named_sets, k):\n",
    "        S = [s for _, s in combo]\n",
    "        inter_set = set.intersection(*S)\n",
    "        union_set = set.union(*S)\n",
    "        if not union_set:\n",
    "            continue\n",
    "        j.append(len(inter_set) / len(union_set))\n",
    "        inter.append(len(inter_set))\n",
    "        uni.append(len(union_set))\n",
    "    if not j:\n",
    "        return np.nan, np.nan, np.nan\n",
    "    return float(np.mean(j)), float(np.mean(inter)), float(np.mean(uni))\n",
    "\n",
    "def compute_scenario(label, named_sets, kmin=None, kmax=None):\n",
    "    M = len(named_sets)\n",
    "    lo = 2 if kmin is None else kmin\n",
    "    hi = M if kmax is None else kmax\n",
    "    rows = []\n",
    "    for k in range(lo, hi + 1):\n",
    "        aj, ai, au = avg_agreement(named_sets, k)\n",
    "        rows.append(dict(scenario=label, M=M, k=k,\n",
    "                         avg_jaccard=aj, avg_intersection=ai, avg_union=au))\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "def aggregate_over_configs(label, list_of_named_sets):\n",
    "    dfs = [compute_scenario(\"tmp\", ns) for ns in list_of_named_sets]\n",
    "    out = dfs[0][[\"k\"]].copy()\n",
    "    out[\"avg_jaccard\"] = np.mean([d[\"avg_jaccard\"].values for d in dfs], axis=0)\n",
    "    out[\"avg_intersection\"] = np.mean([d[\"avg_intersection\"].values for d in dfs], axis=0)\n",
    "    out[\"avg_union\"] = np.mean([d[\"avg_union\"].values for d in dfs], axis=0)\n",
    "    out[\"M\"] = len(list_of_named_sets[0])\n",
    "    out[\"scenario\"] = label\n",
    "    return out[[\"scenario\",\"M\",\"k\",\"avg_jaccard\",\"avg_intersection\",\"avg_union\"]]\n",
    "\n",
    "\n",
    "# ============================= Load named sets ===============================\n",
    "# Baselines (required)\n",
    "BASE_TOKENS = [\"seed0\",\"seed7\",\"seed42\",\"seed123\",\"seed1234\"]\n",
    "for t in BASE_TOKENS:\n",
    "    if t not in INPUTS:\n",
    "        raise KeyError(f\"Missing INPUTS['{t}']\")\n",
    "sets_baseline = [(t, to_id_set(INPUTS[t])) for t in BASE_TOKENS]\n",
    "\n",
    "# Variants (required for respective scenarios)\n",
    "V_SEED3_BS512_DROP02 = (\"seed3_bs512_drp0.2_wd1e-3\", to_id_set(INPUTS[\"diff_bs_drop\"]))\n",
    "V_DROP25_WD3E3       = (\"seed42_drp25_wd3e-3\",       to_id_set(INPUTS[\"diff_drop_wd\"]))\n",
    "V_ARCH               = (\"arch\",                      to_id_set(INPUTS[\"diff_arch\"]))\n",
    "V_TL                 = (\"tl\",                        to_id_set(INPUTS[\"transfer\"]))\n",
    "\n",
    "\n",
    "# ============================= Scenarios =====================================\n",
    "# 1) Identical (2–5 seeds)\n",
    "scen_identical = compute_scenario(\"Identical (2–5 seeds)\", sets_baseline, kmin=2, kmax=5)\n",
    "\n",
    "# 2) +1 different (BS=512, Drop=0.2)\n",
    "scen_bs_drop = compute_scenario(\"+1 different (BS=512, DRP=20%)\", sets_baseline + [V_SEED3_BS512_DROP02])\n",
    "\n",
    "# 3) +1 different (Drop=0.25, WD=3e-3)\n",
    "scen_drop_wd = compute_scenario(\"+1 different (DRP=25%, WD=3e-3)\", sets_baseline + [V_DROP25_WD3E3])\n",
    "\n",
    "# 4) +1 different (Arch)\n",
    "scen_arch = compute_scenario(\"+1 different (Arch)\", sets_baseline + [V_ARCH])\n",
    "\n",
    "# 5) +1 different (TL)\n",
    "scen_tl = compute_scenario(\"+1 different (TL)\", sets_baseline + [V_TL])\n",
    "\n",
    "# 6) +2 different\n",
    "two_variant_configs = [\n",
    "    sets_baseline + [V_SEED3_BS512_DROP02, V_DROP25_WD3E3],\n",
    "    sets_baseline + [V_SEED3_BS512_DROP02, V_ARCH],\n",
    "    sets_baseline + [V_SEED3_BS512_DROP02, V_TL],\n",
    "    sets_baseline + [V_DROP25_WD3E3,       V_ARCH],\n",
    "    sets_baseline + [V_DROP25_WD3E3,       V_TL],\n",
    "    sets_baseline + [V_ARCH,               V_TL],\n",
    "]\n",
    "scen_plus2 = aggregate_over_configs(\"+2 different\", two_variant_configs)\n",
    "\n",
    "# 7) +3 different\n",
    "three_variant_configs = [\n",
    "    sets_baseline + [V_SEED3_BS512_DROP02, V_DROP25_WD3E3, V_ARCH],\n",
    "    sets_baseline + [V_SEED3_BS512_DROP02, V_DROP25_WD3E3, V_TL],\n",
    "    sets_baseline + [V_SEED3_BS512_DROP02, V_ARCH,         V_TL],\n",
    "    sets_baseline + [V_DROP25_WD3E3,       V_ARCH,         V_TL],\n",
    "]\n",
    "scen_plus3 = aggregate_over_configs(\"+3 different\", three_variant_configs)\n",
    "\n",
    "all_results = pd.concat(\n",
    "    [scen_identical, scen_bs_drop, scen_drop_wd, scen_arch, scen_tl, scen_plus2, scen_plus3],\n",
    "    ignore_index=True\n",
    ")\n",
    "\n",
    "# Save table\n",
    "all_results.to_csv(os.path.join(OUT_TAB_DIR, \"stability_7scenarios.csv\"), index=False, float_format=\"%.4f\")\n",
    "\n",
    "# Compute dynamic y-limits after we have the results\n",
    "DYNAMIC_YLIMS = compute_dynamic_ylims(all_results)\n",
    "\n",
    "\n",
    "# ---------------------------- Styling ---------------------------------------\n",
    "sns.set_theme(context=\"paper\", style=\"whitegrid\", font_scale=1.05)\n",
    "palette = sns.color_palette(\"colorblind\", 8)\n",
    "COL = {\n",
    "    \"Identical (2–5 seeds)\":                 palette[0],\n",
    "    \"+1 different (BS=512, DRP=20%)\":       palette[4],\n",
    "    \"+1 different (DRP=25%, WD=3e-3)\":     palette[1],\n",
    "    \"+1 different (Arch)\":                   palette[6],\n",
    "    \"+1 different (TL)\":                     palette[2],\n",
    "    \"+2 different\":                          palette[3],\n",
    "    \"+3 different\":                          palette[5],\n",
    "}\n",
    "STYLE = {\n",
    "    \"Identical (2–5 seeds)\": \"solid\",\n",
    "    \"+1 different (BS=512, DRP=20%)\": (0, (7,2)),\n",
    "    \"+1 different (DRP=25%, WD=3e-3)\": (0, (5,2)),\n",
    "    \"+1 different (Arch)\": (0, (3,1,1,1)),\n",
    "    \"+1 different (TL)\": (0, (1,1)),\n",
    "    \"+2 different\": (0, (3,1,1,1)),\n",
    "    \"+3 different\": (0, (9,2,1,2)),\n",
    "}\n",
    "MARK, LW, MS = \"o\", 2.3, 6.0\n",
    "ORDER_ALL = [\n",
    "    \"Identical (2–5 seeds)\",\n",
    "    \"+1 different (BS=512, DRP=20%)\",\n",
    "    \"+1 different (DRP=25%, WD=3e-3)\",\n",
    "    \"+1 different (Arch)\",\n",
    "    \"+1 different (TL)\",\n",
    "    \"+2 different\",\n",
    "    \"+3 different\",\n",
    "]\n",
    "ORDER = [k for k in ORDER_ALL if (all_results[\"scenario\"] == k).any()]\n",
    "\n",
    "plt.rcParams.update({\"pdf.fonttype\": 42, \"ps.fonttype\": 42})\n",
    "\n",
    "\n",
    "def _endpoint(ax, x, y, txt, color, dy=0):\n",
    "    ax.annotate(txt, xy=(x, y), xytext=(4, dy), textcoords=\"offset points\",\n",
    "                fontsize=BASE_FONTSIZE-1, color=color, va=\"center\", ha=\"left\")\n",
    "\n",
    "def draw_lines(ax, df, ykey, ylabel, pct=False):\n",
    "    for scen in ORDER:\n",
    "        sub = df[df[\"scenario\"] == scen].sort_values(\"k\")\n",
    "        if sub.empty:\n",
    "            continue\n",
    "        ax.plot(sub[\"k\"], sub[ykey],\n",
    "                color=COL[scen], linestyle=STYLE[scen],\n",
    "                marker=MARK, ms=MS, lw=LW, label=scen)\n",
    "        x_end, y_end = sub[\"k\"].iloc[-1], sub[ykey].iloc[-1]\n",
    "        txt = f\"{y_end*100:.1f}%\" if pct else f\"{y_end:.0f}\"\n",
    "        _endpoint(ax, x_end, y_end, txt, COL[scen])\n",
    "    ax.set_xlabel(r\"$k$\")\n",
    "    ax.set_ylabel(ylabel)\n",
    "    ax.set_ylim(*DYNAMIC_YLIMS[ykey])\n",
    "    ax.xaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "    ax.grid(True, linestyle=\":\", linewidth=0.8, alpha=0.6)\n",
    "    ax.minorticks_on()\n",
    "    ax.grid(which=\"minor\", axis=\"y\", linestyle=\":\", alpha=0.25)\n",
    "    if pct:\n",
    "        ax.yaxis.set_major_formatter(PercentFormatter(1.0))\n",
    "        ax.axhline(0.10, color=\"grey\", lw=1, ls=\":\", alpha=0.45)\n",
    "        ax.axhline(0.05, color=\"grey\", lw=1, ls=\":\", alpha=0.45)\n",
    "\n",
    "\n",
    "# ---------- export panels (PDF only) ----------\n",
    "def save_panel(path_pdf, ykey, ylabel, pct=False):\n",
    "    \"\"\"Save a single panel as PDF only.\"\"\"\n",
    "    fig, ax = plt.subplots(figsize=(3.4, 2.4))\n",
    "    draw_lines(ax, all_results, ykey, ylabel, pct=pct)\n",
    "    if ax.get_legend(): ax.get_legend().remove()\n",
    "    fig.tight_layout()\n",
    "    fig.savefig(path_pdf, bbox_inches=\"tight\")\n",
    "    plt.close(fig)\n",
    "\n",
    "def save_legend(path_pdf):\n",
    "    \"\"\"Save standalone legend as PDF only.\"\"\"\n",
    "    fig_tmp, ax_tmp = plt.subplots()\n",
    "    draw_lines(ax_tmp, all_results, \"avg_jaccard\", \"Avg. Jaccard\", pct=True)\n",
    "    handles, labels = ax_tmp.get_legend_handles_labels()\n",
    "    plt.close(fig_tmp)\n",
    "    \n",
    "    fig_leg = plt.figure(figsize=(5.0, 0.45))\n",
    "    fig_leg.legend(handles, labels, loc=\"center\", ncol=3, frameon=True,\n",
    "                   fontsize=BASE_FONTSIZE-0.5, columnspacing=1.0, handletextpad=0.6)\n",
    "    fig_leg.savefig(path_pdf, bbox_inches=\"tight\", pad_inches=0.02)\n",
    "    plt.close(fig_leg)\n",
    "\n",
    "\n",
    "# ---------------------------- Make files -------------------------------------\n",
    "save_panel(os.path.join(OUT_FIG_DIR, \"jaccard_noleg.pdf\"), \"avg_jaccard\", \"Avg. Jaccard\", pct=True)\n",
    "save_panel(os.path.join(OUT_FIG_DIR, \"intersection.pdf\"), \"avg_intersection\", \"Avg. intersection\")\n",
    "save_panel(os.path.join(OUT_FIG_DIR, \"union.pdf\"), \"avg_union\", \"Avg. union\")\n",
    "save_legend(os.path.join(OUT_FIG_DIR, \"legend.pdf\"))\n",
    "\n",
    "print(\"✓ Generated 4 essential figures:\")\n",
    "print(f\"  {OUT_FIG_DIR}/jaccard_noleg.pdf\")\n",
    "print(f\"  {OUT_FIG_DIR}/intersection.pdf\")\n",
    "print(f\"  {OUT_FIG_DIR}/union.pdf\")\n",
    "print(f\"  {OUT_FIG_DIR}/legend.pdf\")\n",
    "print(f\"✓ Table: {OUT_TAB_DIR}/stability_7scenarios.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f01f2437",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\awsna\\AppData\\Local\\Temp\\ipykernel_25492\\1132310212.py:51: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  annot=p_j.applymap(_fmt_percent), fmt=\"\", annot_kws={\"fontsize\": BASE_FONTSIZE-1},\n",
      "C:\\Users\\awsna\\AppData\\Local\\Temp\\ipykernel_25492\\1132310212.py:62: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  annot=p_i.applymap(_fmt_int), fmt=\"\", annot_kws={\"fontsize\": BASE_FONTSIZE-1},\n",
      "C:\\Users\\awsna\\AppData\\Local\\Temp\\ipykernel_25492\\1132310212.py:73: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  annot=p_u.applymap(_fmt_int), fmt=\"\", annot_kws={\"fontsize\": BASE_FONTSIZE-1},\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Unified-color, single unlabeled colorbar figure: figures\\tpgeq_x_fp0_identical_heatmaps_unified.pdf\n"
     ]
    }
   ],
   "source": [
    "# ============================= TP>=x @ FP=0 — compact heatmaps (Identical only) =============================\n",
    "# Thresholds to report\n",
    "TP_THRESHOLDS = [1, 2, 3, 4, 5, 10, 20, 64]\n",
    "\n",
    "def compute_identical_over_thresholds(tp_values):\n",
    "    \"\"\"Return long DF over thresholds for the Identical (2–5 seeds) case only.\"\"\"\n",
    "    rows = []\n",
    "    for tpx in tp_values:\n",
    "        sets_baseline_x = [(name, to_id_set(INPUTS[name], tp_threshold=tpx)) for name,_ in sets_baseline]\n",
    "        df = compute_scenario(\"Identical (2–5 seeds)\", sets_baseline_x, kmin=2, kmax=5)\n",
    "        df[\"tp_threshold\"] = tpx\n",
    "        rows.append(df)\n",
    "    out = pd.concat(rows, ignore_index=True)\n",
    "    return out\n",
    "\n",
    "ident_only = compute_identical_over_thresholds(TP_THRESHOLDS)\n",
    "\n",
    "# Save a tidy table with the exact values\n",
    "out_tbl = ident_only[[\"tp_threshold\",\"k\",\"avg_jaccard\",\"avg_intersection\",\"avg_union\"]].copy()\n",
    "out_tbl.to_csv(os.path.join(OUT_TAB_DIR, \"tpgeq_x_fp0_identical.csv\"), index=False, float_format=\"%.6f\")\n",
    "\n",
    "# ---------- Publication-ready 3-panel heatmap (unified colors, single unlabeled cbar) ----------\n",
    "\n",
    "def _fmt_percent(v): \n",
    "    return \"\" if pd.isna(v) else f\"{v*100:.0f}%\"\n",
    "\n",
    "def _fmt_int(v):\n",
    "    return \"\" if pd.isna(v) else f\"{int(round(v))}\"\n",
    "\n",
    "def _pivot(df, value):\n",
    "    p = df.pivot(index=\"k\", columns=\"tp_threshold\", values=value).sort_index()\n",
    "    return p.reindex(columns=TP_THRESHOLDS)\n",
    "\n",
    "# Pivot data\n",
    "p_j = _pivot(ident_only, \"avg_jaccard\")\n",
    "p_i = _pivot(ident_only, \"avg_intersection\")\n",
    "p_u = _pivot(ident_only, \"avg_union\")\n",
    "\n",
    "# Panel-specific ranges (keep correct normalization), but unify the colormap\n",
    "CMAP = \"viridis\"\n",
    "lims_j = (0, 1)\n",
    "lims_i = _nice_bounds_numeric(np.nanmin(p_i.values), np.nanmax(p_i.values))\n",
    "lims_u = _nice_bounds_numeric(np.nanmin(p_u.values), np.nanmax(p_u.values))\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(7.2, 2.6))\n",
    "plt.subplots_adjust(wspace=0.08, left=0.08, right=0.96, top=0.88, bottom=0.22)\n",
    "\n",
    "# Panel A – Avg. Jaccard\n",
    "sns.heatmap(\n",
    "    p_j, ax=axes[0], cmap=CMAP, vmin=lims_j[0], vmax=lims_j[1],\n",
    "    annot=p_j.applymap(_fmt_percent), fmt=\"\", annot_kws={\"fontsize\": BASE_FONTSIZE-1},\n",
    "    cbar=False, linewidths=0.5, linecolor=\"white\"\n",
    ")\n",
    "axes[0].set_title(\"Avg. Jaccard (Identical)\", fontsize=BASE_FONTSIZE+0.3)\n",
    "axes[0].set_xlabel(\"\")  # no xlabel on left panel\n",
    "axes[0].set_ylabel(\"Runs combined (k)\")\n",
    "axes[0].tick_params(axis=\"both\", labelsize=BASE_FONTSIZE-1)\n",
    "\n",
    "# Panel B – Avg. Intersection\n",
    "sns.heatmap(\n",
    "    p_i, ax=axes[1], cmap=CMAP, vmin=lims_i[0], vmax=lims_i[1],\n",
    "    annot=p_i.applymap(_fmt_int), fmt=\"\", annot_kws={\"fontsize\": BASE_FONTSIZE-1},\n",
    "    cbar=False, linewidths=0.5, linecolor=\"white\"\n",
    ")\n",
    "axes[1].set_title(\"Avg. Intersection\", fontsize=BASE_FONTSIZE+0.3)\n",
    "axes[1].set_xlabel(\"TP ≥ x  at  FP = 0\")  # xlabel only under the middle panel\n",
    "axes[1].set_ylabel(\"\")\n",
    "axes[1].tick_params(axis=\"both\", labelsize=BASE_FONTSIZE-1)\n",
    "\n",
    "# Panel C – Avg. Union (draw the single shared, unlabeled colorbar here)\n",
    "hm = sns.heatmap(\n",
    "    p_u, ax=axes[2], cmap=CMAP, vmin=lims_u[0], vmax=lims_u[1],\n",
    "    annot=p_u.applymap(_fmt_int), fmt=\"\", annot_kws={\"fontsize\": BASE_FONTSIZE-1},\n",
    "    cbar=True, linewidths=0.5, linecolor=\"white\",\n",
    "    cbar_kws={\"orientation\": \"vertical\", \"fraction\": 0.046, \"pad\": 0.02}\n",
    ")\n",
    "axes[2].set_title(\"Avg. Union\", fontsize=BASE_FONTSIZE+0.3)\n",
    "axes[2].set_xlabel(\"\")  # no xlabel on right panel\n",
    "axes[2].set_ylabel(\"\")\n",
    "axes[2].tick_params(axis=\"both\", labelsize=BASE_FONTSIZE-1)\n",
    "\n",
    "# Make the colorbar unlabeled and tickless (unified look, no labels)\n",
    "cb = hm.collections[0].colorbar\n",
    "cb.set_label(\"\")                 # no label text\n",
    "cb.set_ticks([])                 # remove tick labels\n",
    "cb.outline.set_linewidth(0.6)    # keep a subtle outline\n",
    "\n",
    "# Align tick labels across all panels\n",
    "for ax in axes:\n",
    "    ax.set_xticklabels([str(t) for t in TP_THRESHOLDS], rotation=0)\n",
    "    ax.set_yticklabels(ax.get_yticklabels(), rotation=0)\n",
    "\n",
    "out_heatmap = os.path.join(OUT_FIG_DIR, \"tpgeq_x_fp0_identical_heatmaps_unified.pdf\")\n",
    "fig.savefig(out_heatmap, bbox_inches=\"tight\")\n",
    "plt.close(fig)\n",
    "print(\"✓ Unified-color, single unlabeled colorbar figure:\", out_heatmap)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lira-analysis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
